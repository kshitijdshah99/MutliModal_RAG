# Multimodal RAG (Retrieval-Augmented Generation) ğŸš€

Welcome to the **Multimodal RAG** project! This repository provides an end-to-end implementation of a multimodal retrieval-augmented generation system. It can extract, process, and query information from diverse sources, including PDFs, images, web pages, and YouTube videos, while leveraging advanced AI models to deliver intelligent, context-aware responses. ğŸ’¡

---

## ğŸŒŸ Key Features

- **Multimodal Input Support** ğŸ–¼ï¸ğŸ“„ğŸ“¹:
  - **PDFs**: Extract text and images, ready for efficient retrieval.
  - **Images**: Convert visuals into descriptive text with Groqâ€™s LLaVA model.
  - **Web Pages**: Scrape and process textual and visual content from URLs.
  - **YouTube Videos**: Retrieve and process video transcripts seamlessly.

- **AI-Powered Query Response** ğŸ¤–:
  - Combines extracted data into meaningful chunks.
  - Delivers context-aware answers using Groqâ€™s LLaMA model.

- **Streamlit UI** ğŸ–¥ï¸:
  - Interactive and user-friendly interface for file uploads and query submissions.
  - Preview documents, describe images, and access YouTube transcripts directly.

- **Authentication System** ğŸ”’:
  - Secure login and signup functionality to protect user data.

---

## ğŸ› ï¸ Technologies Used

- **Programming Language**: Python ğŸ
- **Frameworks and Libraries**:
  - [Streamlit](https://streamlit.io) ğŸŒ: For building the interactive UI.
  - [Transformers](https://huggingface.co/transformers) ğŸ¤—: For tokenization and AI model integration.
  - [FAISS](https://faiss.ai) ğŸ”: For efficient similarity search and indexing.
  - [PyMuPDF (fitz)](https://pymupdf.readthedocs.io/) ğŸ“„: To extract text and images from PDFs.
  - [YouTube Transcript API](https://pypi.org/project/youtube-transcript-api/) ğŸ¥: For fetching video transcripts.
  - [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) ğŸ¥£: For web scraping.
- **Models**:
  - Groqâ€™s **LLaVA v1.5**: A multimodal language-vision model for image understanding.
  - Groqâ€™s **LLaMA v3**: Advanced language model for RAG.
  - SentenceTransformersâ€™ **all-mpnet-base-v2**: For generating embeddings.

---

## ğŸ” How It Works

### 1. Data Ingestion ğŸ“¥

#### PDFs
- Extracts text and images from uploaded PDF files.
- Stores images locally for further processing.

#### Images
- Converts uploaded images into base64 format.
- Uses Groqâ€™s LLaVA model to generate descriptive text.

#### Web Pages
- Scrapes text and downloads images from specified URLs.
- Cleans and processes the scraped content.

#### YouTube Videos
- Extracts transcripts using the YouTube Transcript API.

### 2. Content Processing âš™ï¸
- Tokenizes text into sentences for better indexing.
- Embeds the content using SentenceTransformers.
- Indexes embeddings using FAISS for efficient retrieval.

### 3. Query Resolution ğŸ’¬
- Accepts user queries via Streamlitâ€™s chat interface.
- Searches the indexed content for the most relevant context.
- Generates context-aware responses using Groqâ€™s LLaMA model.

---

## ğŸš€ Getting Started

### Prerequisites âœ…

- Python 3.9+
- API key for Groq (required for LLaVA and LLaMA models)

### Installation ğŸ› ï¸

1. Clone this repository:
   ```bash
   git clone https://github.com/kshitijdshah99/MultiModal_RAG.git
   ```

2. Install required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up the Groq API:
   - Replace `GROQ_API_KEY` in the code with your API key.

4. Run the Streamlit app:
   ```bash
   streamlit run MultiModal_RAG.py
   ```

---

## ğŸ§‘â€ğŸ’» Usage

1. **Login or Signup** ğŸ”:
   - Use the Streamlit interface to create an account or log in.

2. **Upload Files** ğŸ“¤:
   - Upload PDFs or images using the sidebar.

3. **Enter URLs** ğŸŒ:
   - Provide web page URLs or YouTube video links for processing.

4. **Ask Questions** ğŸ¤”:
   - Submit queries via the chat interface.

5. **View Results** ğŸ‘€:
   - Preview document text, image descriptions, and YouTube transcripts.

---

## ğŸ“‚ File Structure

- `app.py`: Main Streamlit application.
- `requirements.txt`: List of dependencies.
- `user_credentials.pkl`: File for storing user credentials.
- `extracted_images/`: Directory for storing extracted images.

---

## ğŸš§ Future Enhancements

- Support for additional file formats (e.g., DOCX, XLSX).
- Improved indexing and retrieval algorithms.
- Enhanced visualization of retrieved content.

---

## ğŸ¤ Contributions

Contributions are welcome! Please submit issues or pull requests to help improve this project.

---

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---


